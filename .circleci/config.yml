version: 2.1

references:
  npm_cache_key: &npm_cache_key
                   v1-dependency-npm1-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
  npm_cache_restore_key: &npm_cache_restore_key
    keys:
      - *npm_cache_key
  # Note: important that values of guids and keys have matching order!"
  study_keys: &study_keys
                "osteo brain angio mbc"
  study_guids: &study_guids
                "CMI-OSTEO cmi-brain ANGIO cmi-mbc"

# Container for all the builds
executors:
  commit-executor:
    docker:
      - image: broadinstitute/study-website-build:04-09-2020A
    working_directory: ~/repo/ddp-workspace
    resource_class: medium+

commands:
  app-build-and-store:
    description: Run build and store archive of it
    parameters:
      study_key:
        type: string
    steps:
      - setup-build-workspace
      - setup-shared-env:
          study_key: << parameters.study_key >>
      - build-app
      - store-app-build

  app-build-and-deploy:
    description: Run build and immediately deploy it to GAE
    parameters:
      study_key:
        type: string
      skip_build:
        type: boolean
        default: false
    steps:
      - setup-build-workspace
      - setup-shared-env:
          study_key: << parameters.study_key >>
      - unless:
          condition: << parameters.skip_build >>
          steps:
            - build-app
            - deploy-exploded-build:
                study_key: << parameters.study_key >>

  set-deployment-environment:
    description: "Determine working environment"
    steps:
      - run:
          name: Determine environment for branch << pipeline.git.branch >>
          command: |
            case "<< pipeline.git.branch >>" in
              develop)
                DEPLOY_ENV=dev
              ;;
              test)
                DEPLOY_ENV=test
              ;;
              staging)
                DEPLOY_ENV=staging
              ;;
              production)
                DEPLOY_ENV=prod
              ;;
              *)
                DEPLOY_ENV=dev
                echo "We are going to map << pipeline.git.branch >> to dev environment"
              ;;
            esac
            echo "Setting deployment ENVIRONMENT to $DEPLOY_ENV"
            echo "export ENVIRONMENT=$DEPLOY_ENV" >> $BASH_ENV
            source $BASH_ENV

  deploy-stored-build:
    description: Deploy archived build to GAE
    parameters:
      study_key:
        type: string
    steps:
      - checkout:
          path: ~/repo
      - setup-shared-env:
          study_key: << parameters.study_key >>
      - set-deployment-environment
      - run:
          name: Retrieve and expand build archive for << parameters.study_key >> with git SHA << pipeline.git.revision >>
          command: |
            set -u
            # we are getting our builds from the one bucket
            readvault.sh secret/pepper/prod/v1/conf .data.gcp.serviceKey | gcloud auth activate-service-account --key-file=-
            TAR_FILE_URL_PATTERN="gs://${BUILDS_BUCKET}/${ANGULAR_PROJECT_NAME}/${ANGULAR_PROJECT_NAME}_*_${SHORT_GIT_SHA}.tar.gz"
            TAR_FILE_URL=`gsutil ls $TAR_FILE_URL_PATTERN  | sort -r | head -1`

            if [ -z $TAR_FILE_URL ]
            then
              echo "Could not find archive using pattern ${TAR_FILE_URL_PATTERN}"
              exit 1
            fi
            TAR_FILE_PATH="/tmp/$(basename -- $TAR_FILE_URL)"
            gsutil cp  $TAR_FILE_URL $TAR_FILE_PATH
            cd ~/repo/ddp-workspace
            mkdir -p $OUTPUT_DIR && tar -xvf $TAR_FILE_PATH -C $OUTPUT_DIR
            echo "Contents of extracted archive at $OUTPUT_DIR"
            ls -l $OUTPUT_DIR
      - deploy-exploded-build:
          study_key: << parameters.study_key >>

  deploy-exploded-build:
    description: Deploy files to GAE
    parameters:
      study_key:
        type: string
    steps:
      - set-deployment-environment
      - run:
          name: <<parameters.study_key>> generate config files and copy pepperConfig.js
          command: |
            set -u
            ./build-study.sh v1 $ENVIRONMENT . <<parameters.study_key>> "$STUDY_GUID" --config
            cd ddp-workspace
            CONFIG_DIR="${OUTPUT_DIR}/assets/config"
            mkdir -p $CONFIG_DIR
            CONFIG_FILE_SRC_PATH="${ANGULAR_PROJECT_DIR_PATH}/output-config/pepperConfig.js"
            cp  $CONFIG_FILE_SRC_PATH $CONFIG_DIR
            echo "$CONFIG_FILE_SRC_PATH has been copied to $CONFIG_DIR"
          environment: #Setting this ENV variable prevents launching a new Docker within build-study-sh script
            USE_DOCKER: false
          working_directory: ~/repo
      - run:
          name: Setup gcloud context
          command: |
            set -u
            readvault.sh secret/pepper/${ENVIRONMENT}/v1/conf .data.gcp.serviceKey | gcloud auth activate-service-account --key-file=-
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE}
      - run:
          name: Deploy to GAE
          command: |
            set -u
            gcloud app deploy --version="${SHORT_GIT_SHA}" --stop-previous-version --project "broad-ddp-${ENVIRONMENT}" "${ANGULAR_PROJECT_DIR_PATH}/app.yaml"
      - run:
          name: Update GAE dispatch config
          command: |
            set -u
            gcloud app deploy --quiet --project "broad-ddp-${ENVIRONMENT}" "${ANGULAR_PROJECT_DIR_PATH}/output-config/dispatch.yaml"
      - run:
          name: Update deployments sheet
          command: |
            set -u
            set +x
            readvault.sh secret/pepper/${ENVIRONMENT}/v1/conf .data.gcp.serviceKey | \
            reportdeploy.sh "$RELEASE_SHEET_ID" '<<parameters.study_key>> Angular client' "$ENVIRONMENT" "$CIRCLE_BUILD_NUM" "$CIRCLE_BUILD_URL"
      - run:
          name: Delete previous versions of service
          command: |
            set +x
            # extract the service name from the GAE yaml file
            CONFIG_FILE="${ANGULAR_PROJECT_DIR_PATH}/app.yaml"
            SERVICE=$(grep -Eo -m1 "^service:\s*.*" "${CONFIG_FILE}" | awk '{print $2}')
            echo "The service name is *${SERVICE}*"

            # find what other versions are currently running
            # skip first line, exclude our version, print 2nd column
            AWK_COMMMAND="NR > 1 && !/${SHORT_GIT_SHA}/ {print \$2}"
            VERSIONS_TO_DELETE=$(gcloud app versions list --service "$SERVICE" --project "broad-ddp-${ENVIRONMENT}" | awk "${AWK_COMMMAND}")

            # Sometime deleting versions fails. If there are less than 3 versions then we are not going to worry about it
            # and set flag so this job step does not fail when exit error value is generated
            if [[ ! -z $VERSIONS_TO_DELETE ]] && [[ "${#VERSIONS_TO_DELETE[@]}" -lt 3 ]]; then
              set +e
            fi

            for VERSION_TO_DELETE in $VERSIONS_TO_DELETE; do
              echo "Deleting version $VERSION_TO_DELETE of service $SERVICE"
              gcloud app versions delete --quiet --service "$SERVICE" "$VERSION_TO_DELETE" --project "broad-ddp-${ENVIRONMENT}"
            done;
            exit 0;

  setup-shared-env:
    description: "Setup shared ENV vars used by multiple scripts"
    parameters:
      study_key:
        type: string
        default: UNKNOWN
      study_keys:
        type: string
        default: *study_keys
      study_guids:
        type: string
        default: *study_guids
    steps:
      - run:
          name: Set environment variables to build <<parameters.study_key>>
          command: |
            echo "export VAULT_TOKEN=`vault write -field=token auth/approle/login role_id=$VAULT_ROLE_ID secret_id=$VAULT_ROLE_SECRET_ID`" >> $BASH_ENV
            echo 'export PATH=$PATH:~/repo/build-utils' >> $BASH_ENV
            if [[ '<<parameters.study_key>>' != 'UNKNOWN' ]]; then
              echo 'export STUDY_KEY=<<parameters.study_key>>' >> $BASH_ENV
              STUDY_KEYS=(<<parameters.study_keys>>)
              STUDY_GUIDS=(<<parameters.study_guids>>)
              for i in ${!STUDY_KEYS[@]}; do
                  currentKey=${STUDY_KEYS[$i]}
                  if [[ $currentKey == '<<parameters.study_key>>' ]]; then
                      STUDY_GUID="${STUDY_GUIDS[$i]}"
                      echo "export STUDY_GUID=${STUDY_GUID}" >> $BASH_ENV
                      break;
                  fi
              done;
              if [[ -z $STUDY_GUID ]]; then
                echo "Could not find study guid for <<parameters.study_key>>"
                exit 1
              fi
              echo 'export ANGULAR_PROJECT_NAME=ddp-<<parameters.study_key>>' >> $BASH_ENV
              echo 'export ANGULAR_PROJECT_DIR_PATH=projects/ddp-<<parameters.study_key>>' >> $BASH_ENV
              source $BASH_ENV
              OUTPUT_DIR="${ANGULAR_PROJECT_DIR_PATH}/dist"
              echo "export OUTPUT_DIR=$OUTPUT_DIR" >> $BASH_ENV
            fi
            echo "export SHORT_GIT_SHA=`echo '<< pipeline.git.revision >>' | cut -c 1-7`" >> $BASH_ENV
            echo 'export BUILDS_BUCKET=ddp-build-artifacts' >> $BASH_ENV
            source $BASH_ENV

  setup-build-workspace:
    description: "Setup workspace used by all projects"
    steps:
      - checkout:
          path: ~/repo
      - restore_cache: *npm_cache_restore_key
      - run:
          name: Install dependencies
          command: "[ ! -d ./ddp-workspace/node_modules ] && npm ci"
      - save_cache:
          key: *npm_cache_key
          paths:
            - ./node_modules

  build-app:
    description: "Build DDP study app"
    steps:
      - run:
          name: ng build
          command: |
            set -u
            ng build $ANGULAR_PROJECT_NAME --prod --aot --base-href=/ --output-path=$OUTPUT_DIR --verbose=true --progress=true

  store-app-build:
    description: "Copy build to cloud storage"
    steps:
      - run:
          name: Create build archive
          command: |
            set -u
            DATE=`date +%F`
            TAR_NAME="${ANGULAR_PROJECT_NAME}_${DATE}_${SHORT_GIT_SHA}.tar.gz"
            TAR_PATH="/tmp/${TAR_NAME}"
            # Save some ENV vars for in job downstream
            echo "export TAR_NAME=$TAR_NAME" >> $BASH_ENV
            echo "export TAR_PATH=$TAR_PATH" >> $BASH_ENV
            cd ${OUTPUT_DIR}
            tar -czvf ${TAR_PATH} .
            echo "Tar file created at ${TAR_PATH}"
            ls -l $TAR_PATH
      - run:
          name: Store build archive
          command: |
            set -u
            readvault.sh secret/pepper/prod/v1/conf .data.gcp.serviceKey | gcloud auth activate-service-account --key-file=-
            gsutil cp  ${TAR_PATH} "gs://${BUILDS_BUCKET}/${ANGULAR_PROJECT_NAME}/${TAR_NAME}"

  conditionally-launch-build-and-deploy:
    description: Launch build and deploy if project has changed
    parameters:
      study_keys:
        type: string
    steps:
      - run:
          name: Check << parameters.study_keys >> and launch build if modified
          command: |
            set -u
            set +e
            set +x
            # CircleCi does not support arrays as params, so here is my workaround
            STUDY_KEYS=(<< parameters.study_keys >>)

            CHANGED_PROJECTS=$(findmodifiedprojects.sh <<pipeline.git.base_revision >> << pipeline.git.revision >>)

            echo "The following projects were found to have changed: $CHANGED_PROJECTS"

            for i in "${!STUDY_KEYS[@]}"; do
              STUDY_KEY=${STUDY_KEYS[$i]}

              NG_PROJECT_NAME="ddp-$STUDY_KEY"
              CHANGED_DEPENDENCIES=$(echo  $CHANGED_PROJECTS |
                  grep -E -e $NG_PROJECT_NAME -e _SHARED_  -e ddp-sdk -e toolkit)
              if [[ ! -z $CHANGED_DEPENDENCIES ]]; then
                echo "Launching build and deploy for $NG_PROJECT_NAME"
                curl -u "${CIRCLE_API_TOKEN}:" -X POST --header "Content-Type: application/json" -d "{
                                  \"branch\": \"<< pipeline.git.branch >>\",
                                  \"parameters\": {
                                      \"study_key\": \"$STUDY_KEY\",
                                      \"do-builds\": true
                                  }
                                }" https://circleci.com/api/v2/project/gh/broadinstitute/ddp-angular/pipeline
              else
                echo "Skipping $STUDY_KEY"
              fi
            done;

  conditionally-launch-build-and-store:
    description: Launch build and save job if build missing
    parameters:
      study_key:
        type: string
    steps:
      - setup-shared-env:
          study_key: << parameters.study_key >>
      - run:
          name: Initiate build for <<parameters.study_key>> and git SHA << pipeline.git.revision >> if existing one not found
          command: |
            set -u
            set +e
            readvault.sh secret/pepper/prod/v1/conf .data.gcp.serviceKey | gcloud auth activate-service-account --key-file=-
            TAR_FILE_URL_PATTERN="gs://${BUILDS_BUCKET}/${ANGULAR_PROJECT_NAME}/${ANGULAR_PROJECT_NAME}_*_${SHORT_GIT_SHA}.tar.gz"
            echo "Checking for ${TAR_FILE_URL_PATTERN}"
            # For some reason following line generating exit code 1 every time in CircleCI. Use set +e so script can continue
            TAR_FILE_URL=`gsutil ls $TAR_FILE_URL_PATTERN  | head -1`

            # if not found, let's kick off a build
            if [ -z $TAR_FILE_URL ]
              then
                echo "No build found for <<parameters.study_key>> with git sha ${SHORT_GIT_SHA}. Initiating a build for it."
                curl -u "${CIRCLE_API_TOKEN}:" -X POST --header "Content-Type: application/json" -d '{
                  "branch": "<< pipeline.git.branch >>",
                  "parameters": {
                      "study_key": "<<parameters.study_key>>",
                      "do-builds": true
                  }
                }' https://circleci.com/api/v2/project/gh/broadinstitute/ddp-angular/pipeline
              else
                echo "Build for <<parameters.study_key>> found at URL: ${TAR_FILE_URL}. No new build will be initiated"
            fi

jobs:
  build-and-deploy-job:
    parameters:
      study_key:
        type: string
    executor:
      name: commit-executor
    steps:
      - app-build-and-deploy:
          study_key: << parameters.study_key >>
          skip_build: false

  conditionally-launch-build-and-deploy-all-job:
    executor:
      name: commit-executor
    steps:
      - checkout
      - setup-shared-env
      - conditionally-launch-build-and-deploy:
          study_keys: *study_keys

  conditionally-launch-build-and-store-all-job:
    executor:
      name: commit-executor
    steps:
      - checkout
      - conditionally-launch-build-and-store:
          study_key: osteo
      - conditionally-launch-build-and-store:
          study_key: brain
      - conditionally-launch-build-and-store:
          study_key: angio
      - conditionally-launch-build-and-store:
          study_key: mbc

  app-build-and-store-job:
    executor:
      name: commit-executor
    steps:
      - app-build-and-store:
          study_key: << pipeline.parameters.study_key >>

  deploy-stored-build-job:
    parameters:
      study_key:
        type: string
    executor:
      name: commit-executor
    steps:
      - deploy-stored-build:
          study_key: << parameters.study_key >>

parameters:
  study_key:
    type: string
    default: "UNKNOWN"
  study_guid:
    type: string
    default: "UNKNOWN"
  do-builds:
    type: boolean
    default: false

workflows:
  version: 2

  build-and-deploy-all-apps-workflow:
    unless: << pipeline.parameters.do-builds >>
    jobs:
      - conditionally-launch-build-and-deploy-all-job:
          filters:
            branches:
              only:
                - develop

  build-and-deploy-workflow:
    when: << pipeline.parameters.do-builds >>
    jobs:
      - build-and-deploy-job:
          study_key: << pipeline.parameters.study_key >>

  launch-all-app-builds-workflow:
    # using do-builds param to select which of the two workflows using the build-on-tag-filters
    # should run; should be this one that just launches the builds or the one actually doing the builds
    unless: << pipeline.parameters.do-builds >>
    jobs:
      - conditionally-launch-build-and-store-all-job: &build-and-store-filters
          filters:
            branches:
              only:
                - /^rc.*/
                - /^hotfix.*/

  build-app-workflow:
    when: << pipeline.parameters.do-builds >>
    jobs:
      - app-build-and-store-job:
          <<: *build-and-store-filters

  deploy-all-apps-workflow:
    jobs:
      - deploy-stored-build-job: &deploy_branch_filters
          filters:
            branches:
              only:
                - test
                - staging
                - production
          study_key: osteo

      - deploy-stored-build-job:
          <<: *deploy_branch_filters
          study_key: brain
      - deploy-stored-build-job:
          <<: *deploy_branch_filters
          study_key: mbc
      - deploy-stored-build-job:
          <<: *deploy_branch_filters
          study_key: angio

  nightly:
    triggers:
      - schedule:
          cron: "0 22 * * *"
          filters:
            branches:
              only:
                - develop
    jobs:
      - build-and-deploy-job:
          name: osteo-nightly
          study_key: osteo
      - build-and-deploy-job:
          name: angio-nightly
          study_key: angio
      - build-and-deploy-job:
          name: brain-nightly
          study_key: brain
      - build-and-deploy-job:
          name: mbc-nightly
          study_key: mbc
